{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import librosa\n",
    "import IPython.display as ipd #음성파일 load 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 일반 test 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#음성파일 path 설정하기\n",
    "train_audio_path = 'tensorflow-speech-recognition-challenge/train/train/audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-b56c21eb2d11>:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(label) :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca13cb56700249a090bf2ff96a4fd301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tqdm : process bar 만들어주는 library\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "all_wave = []\n",
    "all_label = []\n",
    "\n",
    "#train_audio_path = 'tensorflow-speech-recognition-challenge/train/train/audio/'\n",
    "label = os.listdir(train_audio_path) # 하위 디렉토리 이름들 가져오기\n",
    "\n",
    "#전체 파일들 가져오기\n",
    "for i in tqdm_notebook(label) :\n",
    "    wave = [a for a in os.listdir(train_audio_path+'/'+i) if a.endswith('.wav')]\n",
    "    for wav in wave :\n",
    "        #파일 한개 로드하기\n",
    "        #sr : sampling rate 설정하기 ( default rate :  22500 )\n",
    "        sample, sample_rate = librosa.load(train_audio_path+'/'+i+'/'+wav, sr=16000)\n",
    "        # sr을 바꿔서 resampling\n",
    "        sample = librosa.resample(sample, sample_rate, 8000)\n",
    "        if (len (sample)==8000):\n",
    "            all_wave.append(sample)\n",
    "            all_label.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### silence로 사용할 소음 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "silence_audio_path = 'tensorflow-speech-recognition-challenge/train/train/audio/_background_noise_/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-996d27f6e537>:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for wav in tqdm_notebook(wave) :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d6590b820b468ca13f9f485fc200b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sil_label = []\n",
    "sil_wave = []\n",
    "\n",
    "#전체 파일들 가져오기\n",
    "wave = [a for a in os.listdir(silence_audio_path) if a.endswith('.wav')]\n",
    "\n",
    "for wav in tqdm_notebook(wave) :\n",
    "    #파일 한개 로드하기\n",
    "    #sr : sampling rate 설정하기 ( default rate :  22500 )\n",
    "    sample, sample_rate = librosa.load(silence_audio_path+wav, sr=16000)\n",
    "    # sr을 바꿔서 resampling\n",
    "    sample = librosa.resample(sample, sample_rate, 8000)\n",
    "    \n",
    "    for i in range(8000,len(sample),8000):\n",
    "        sil_wave.append(sample[i-8000:i])\n",
    "        sil_label.append('silence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58252, 8000, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 차원 변환\n",
    "all_wave = np.array(all_wave).reshape(-1, 8000, 1)\n",
    "sil_wave = np.array(sil_wave).reshape(-1, 8000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58252, 8000, 1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_wave).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396, 8000, 1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sil_wave).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_wave = np.concatenate((all_wave,sil_wave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58648, 8000, 1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(total_wave).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_label = np.concatenate((all_label,sil_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#문자로 존재하는 label을 숫자화\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(total_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go',\n",
       "       'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on',\n",
       "       'one', 'right', 'seven', 'sheila', 'silence', 'six', 'stop',\n",
       "       'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero'], dtype='<U7')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(total_wave, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, Input , MaxPooling1D, Dense, Dropout, Flatten\n",
    "\n",
    "inputs = Input(shape=(8000, 1))\n",
    "\n",
    "conv = Conv1D(8, 13, activation='relu')(inputs)\n",
    "maxpooling = MaxPooling1D(3)(conv) #지엽적인 정보 제거\n",
    "drop_out = Dropout(0.3) (maxpooling)\n",
    "\n",
    "conv = Conv1D(32, 9, activation='relu')(drop_out)\n",
    "maxpooling = MaxPooling1D(3)(conv) #지엽적인 정보 제거\n",
    "drop_out = Dropout(0.3) (maxpooling)\n",
    "\n",
    "conv = Conv1D(64, 7, activation='relu')(drop_out)\n",
    "maxpooling = MaxPooling1D(3)(conv) #지엽적인 정보 제거\n",
    "drop_out = Dropout(0.3) (maxpooling)\n",
    "\n",
    "conv = Conv1D(64, 7, activation='relu')(drop_out)\n",
    "maxpooling = MaxPooling1D(3)(conv) #지엽적인 정보 제거\n",
    "drop_out = Dropout(0.3) (maxpooling)\n",
    "\n",
    "flatten = Flatten()(drop_out) #차원축소\n",
    "\n",
    "dense = Dense(256, activation='relu')(flatten) \n",
    "drop_out = Dropout(0.3)(dense)\n",
    "\n",
    "dense = Dense(128, activation='relu') (drop_out)\n",
    "drop_out = Dropout(0.3) (dense) #정답클래스의 개수가 많아지면 dese 추가\n",
    "\n",
    "outputs = Dense(len(label), activation='softmax')(drop_out)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 음성데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "734/734 [==============================] - 2120s 3s/step - loss: 1.2776 - acc: 0.6815 - val_loss: 0.6164 - val_acc: 0.8229\n",
      "Epoch 2/10\n",
      "734/734 [==============================] - 1907s 3s/step - loss: 0.7158 - acc: 0.7898 - val_loss: 0.5783 - val_acc: 0.8320\n",
      "Epoch 3/10\n",
      "734/734 [==============================] - 1950s 3s/step - loss: 0.6637 - acc: 0.8008 - val_loss: 0.5974 - val_acc: 0.8252\n",
      "Epoch 4/10\n",
      "734/734 [==============================] - 2049s 3s/step - loss: 0.6486 - acc: 0.8049 - val_loss: 0.5465 - val_acc: 0.8415\n",
      "Epoch 5/10\n",
      "734/734 [==============================] - 2054s 3s/step - loss: 0.6053 - acc: 0.8161 - val_loss: 0.5301 - val_acc: 0.8449\n",
      "Epoch 6/10\n",
      "734/734 [==============================] - 1990s 3s/step - loss: 0.5944 - acc: 0.8183 - val_loss: 0.4993 - val_acc: 0.8575\n",
      "Epoch 7/10\n",
      "734/734 [==============================] - 2065s 3s/step - loss: 0.5905 - acc: 0.8208 - val_loss: 0.6545 - val_acc: 0.8098\n",
      "Epoch 8/10\n",
      "734/734 [==============================] - 2054s 3s/step - loss: 0.5818 - acc: 0.8233 - val_loss: 0.5650 - val_acc: 0.8356\n",
      "Epoch 9/10\n",
      "734/734 [==============================] - 2081s 3s/step - loss: 0.5648 - acc: 0.8284 - val_loss: 0.5480 - val_acc: 0.8366\n",
      "Epoch 10/10\n",
      "734/734 [==============================] - 2153s 3s/step - loss: 0.5598 - acc: 0.8277 - val_loss: 0.5375 - val_acc: 0.8418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ff0f0adbb0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test 데이터 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio_path = 'tensorflow-speech-recognition-challenge/test/test/audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-61-8add6cc927c2>:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for wav in tqdm_notebook(wave) :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0932e7266a7346a0a60558478d852bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=158538.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "test_wave = []\n",
    "\n",
    "wave = os.listdir(test_audio_path)\n",
    "\n",
    "#전체 파일들 가져오기\n",
    "for wav in tqdm_notebook(wave) :\n",
    "    test, test_rate = librosa.load(test_audio_path+wav, sr=16000)\n",
    "    sample = librosa.resample(test, test_rate, 8000)\n",
    "    #1초로 잘라서 추가하기\n",
    "    if (len (sample)==8000):\n",
    "        test_wave.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158538"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 불러오기 : happy 음성\n",
    "test_audio_path = 'tensorflow-speech-recognition-challenge/test_11/'\n",
    "test, test_rate = librosa.load(test_audio_path+'happy.wav', sr=8000)\n",
    "#test = librosa.resample(test, test_rate, 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,UklGRqQ+AABXQVZFZm10IBAAAAABAAEAQB8AAIA+AAACABAAZGF0YYA+AAAaAOEA1QDAALEAjgB9AF0ARwAuABsA///2/9r/zf+8/6r/mP+Q/4n/hf+J/4P/jP+R/5P/nv+p/67/t//C/8j/0v/Z/97/5P/r/+r/6f/t/+b/5P/e/9n/1f/P/83/x//C/77/vf+9/7r/uv++/8D/wv/H/9D/3f/p//v/BQAMABsAJgA3AEgATwBaAF4AYQBkAGcAZgBhAFsAUwBKAEAALAAbAAkA9P/p/83/tP+n/5b/iv97/2z/aP9m/2b/Z/9m/27/e/+H/5f/p/+w/8n/3f/o//7/EAAjADUASABcAGQAbwB2AHwAgQCHAIkAhwCHAIIAfwB6AHcAcQBkAFwAVgBFAD0ANAAqACUAGAAMAAAA+P/x/+n/4v/e/9j/1//W/9b/1v/P/8j/zv/R/9T/1v/a/97/1//c/9//4P/e/9j/1v/O/83/yv+//7b/sf+m/57/pP+b/5P/lP+T/5X/nv+f/6P/rP+z/8H/zP/a/+b/9f8EABEAJQA9AEgAVwBhAG0AewCFAI4AkgCWAJgAlgCSAJMAkACLAIQAeABsAGUAWABPAEIAMAAmABEABgD8//D/6//e/9f/zf/L/8n/xf/B/77/wf+9/77/uf/A/8H/wf/B/8L/yP/F/8v/0P/N/8b/xv/E/8D/vv+5/7b/sv+w/67/rf+n/6n/rP+s/7j/u/++/8j/1P/Z/+P/7v/4/wAACgAXACQAMgA2AEIASgBVAFkAXgBoAGgAaABoAGsAaQBqAGEAXQBYAEgAQAA3ACoAGQAMAPr/8f/g/9L/zP/B/7n/tf+0/63/sP+2/7X/v//B/8P/y//S/+P/5//x//f/+/8BAAcADAAQABwAGAAVABoAFwAYABYADwAMAAgABgABAAAA/v/4//f/9v/2//P/9v/5//b/+/8AAAEABgALAAwAEgASABoAIQAiAB8AHQAeABYAEwAPAAwACgAAAP7/+P/1//b/8P/s/+n/6v/o/+n/5P/l/+f/5//q/+z/6v/v//L/9f////3/AQAFAAcACAASABEADgAVABYAHAAfAB8AHgAfACAAKAAkACMAKAAoACoAJwAiAB8AHAAhABwAGgAVAA8ADQADAAEAAQD8//j/8//t/+r/6f/h/9r/3f/b/9//3P/e/+L/4P/k/+f/7P/x//P/9f///wMABwANAAoACwAOAA0ADQALAAcAAAD7//j/9//x/+j/6P/c/+H/4//a/9r/3P/k/+b/6//p//T//v8EAAcADwAVACEAJQAsADYAMgA3ADoAPAA8ADsAMQA0AC0AKAAqAB4AEwANAAwABAACAPb/7v/q/+b/6P/m/97/2f/d/9//5P/m/+b/6f/t//H/8//+/wEABAAIAAUACAAOAA0ADwATABIADAAKAAgAAgABAAIA///4//f/9//w/+z/7//t/+z/7P/r/+r/7//x//L/8P/v//n/+/8AAAMACQAKAAYABwAMABEADgAVABgAFwAWABUAFgATAA8AEAAQABAADwAGAAYABgACAAIAAwACAAAAAgD///f/+//5//3/AAD7//n/9//7//v/+f/9//7/+f/8//z/AAD+////AgABAAQABQAHAAIACAALAA0ACgAKAA0ABQAGAAkABgADAAEAAwD9//f/+P/5//r/+v/4//T/+v/1//f//P/7/wEAAgABAAUAAwAHAA4ADgAUAA8ADQAUAAsABwAKAAsACgAAAAUAAwD///r/9P/y/+//8f/1//b/8v/z//X/9f/2//n//v8AAAAAAAADAAIABAAIAAgACQAOAAwABgAKAAwACwAMAAoACwAJAAMAAAAAAAEA+//8//3//P/9//X/9f/2//z/+//7//r/AAADAAIABQAAAAcACQAKAA0ACwAMAA0ADAALAAkADgAOAAUAAwAGAAIA/f////7////3//D/9P/1//H/7//w//L/7//1//P/8v/2//T/9v/1//n/AQACAAEAAwADAAgACQAMAA4AEAANAAcACQAQABIAEgAMAAYABwAIAAYABAAFAAIAAAAAAAIAAgAAAP3//v/+//j/9f/2//b/+P/3//P/8f/z//r/+f/1//n////7//v/AAABAAQAAwALAAoADAAQAA4ACwAHAAoADQAJAAkACgAEAAcAAgAFAAQAAwAHAAEABAAAAAEA//8AAAAA+f/9//7//v/+//r/+f///wEAAwAGAAEA//8EAAQABQAFAAYABQACAP///v8CAP7//P/9//3/+v/2//L/8//x/+//8//w//L/8f/v//P/+//6//7//v/9/wUAAwADAAQACAAMAAwABQAGAAoACQALAAoACwAGAAgACAAGAAcABAAIAAQAAAABAAUABgAFAAMAAgAHAAUABwAIAAoACAAEAAoADQAGAAEABgADAAEAAwAGAAIA/v8BAAAA+//8//3//P/3//X/9v/1//D/7v/y/+7/6//q/+r/6//r//H/8v/x//L/7//w//b//f/7//f/+//+/wEABQAFAAoABgALABQAEgAYABMAFAAZABcAGQAWABQAEgASABIAEAANAAcACAAGAAIAAQD9//v/9//5//f/8f/z/+3/6f/o/+3/8P/p/+r/6f/q/+f/5P/o/+j/6v/i/+f/6v/m/+v/5v/q/+3/6//w//D/9f/5//z/+v/5/wMAAwAIABAAEQAXABgAGwAfACIAIgAhACMAJQAqACwALQArAC8ALQAtAC4AKgAtACoAJgAnAB8AHQAaAA4AEAAPAAwAAQD7//r/8f/t/+f/4f/X/9P/0//P/8v/xf/D/8H/vv+//8D/wv/E/8H/yv/K/9D/0f/Q/9v/3v/j/+f/7//6/wAABwAOABYAHAAeACoAMAA4AD8AQwBJAE4ATgBSAFoAVQBXAFcAVABYAFMAUQBNAEQARQA9ADgAMgAsACcAIwAhABgADwALAAkA/v/6//T/7//l/93/2v/U/9H/zf/E/7v/vP+6/7n/sv+y/7D/sP+w/6n/rv+u/67/sv+y/7T/vf/C/8b/yf/R/9P/3P/l/+r/+P/5/wMACwAPAB0AJQAtADUAOgA8AEQARQBHAE8AUABSAFAAVQBUAFEAVABOAFQAUABIAEcARgBCAD0APAA4ADIAKwAoACAAHQAVABEADQAGAAAA9f/u/+X/2//S/8b/wv++/7f/sf+r/6v/pP+m/6L/pv+o/6b/qf+p/6z/rf+1/7X/uv/C/8j/yf/R/9f/3f/p//H/9f/8/wMADgAVABkAHwAjAC4AMQA1ADsAQQBEAEcASwBKAEwATABJAEoARwBKAEYAPwBCADwAOAAzACcAJQAbAA4ACQD+//X/7P/q/9z/1v/S/8v/zP/C/7//vv/B/7//vP+7/7n/vP++/8D/uv++/8P/xP/I/8z/0P/W/9v/4P/p//L/+f///wIACAAUAB4AJAApACwALQAtADIAMwAzADUAOAA4ADMANAA2ADoANwA3ADsAOgA8AD0AOwA6ADoAOAAyAC4AJgAcABMACAD+//H/6P/f/9X/yf+8/7j/sv+n/6X/of+g/6L/of+i/6L/qv+w/7T/uv/A/8X/zP/R/9X/3f/l/+7/9f/3//7/BgAOABEAGgAkACgALQA0ADkAPABCAEEARgBFAD8APwBBAD4AOQA5ADkAMwAvADAAKgAoACQAJgAkACEAIQAZABkAHAAVABMACQAAAPz/8P/o/97/2P/N/8f/vv+5/7H/pv+k/57/nv+h/6D/n/+p/7L/uf+6/8P/zv/W/9//6f/v//f///8CAAcABwAQABEADQAMABEAFgATABUAGAAdABwAIAAoACYAKgAsADMANQA1ADYAMAAzADEALgAtACkAIwAfABkAFQARAAoABAD9//n/8//n/+D/2//X/9b/0f/K/8b/xf/A/77/vv+8/7z/uf+9/73/uv+//8L/wv/B/8f/zP/L/9D/1P/Y/9z/4v/m/+v/9f/4/wAAAQALABMAGQAiACIALAAwADkAOQA/AEUARABDAEQARAA+AEYAQAA+ADkAMwA0AC4AKAAlACMAIAAaABQADgAIAAIAAAD5/+7/6f/h/9j/0f/O/8f/wP+7/7P/s/+x/7L/s/+w/6//tP+y/7L/s/+2/7z/t/+6/73/vP+8/7v/vP+8/7v/vv/C/8P/xf/I/83/1f/g/+j/+P8GAA4AIgAuADwAUgBfAHAAfACLAJQAnACnAKsAsgCxALEArACmAJ4AlgCJAHgAcABhAFIAQQAwAB0ADgABAPX/5P/a/8z/wf+2/6z/pP+Y/5j/j/+K/4j/gf99/3//eP96/3b/df98/3j/fP+D/4r/iv+a/6H/pv+2/73/yP/V/9//6P/z//f/BAARABkAIwAvADsARABRAF0AbQB7AIkAmwClALQAwQDGAM0A1QDYANsA4gDeANcA0wDJALsAtACoAJQAfwBsAFsASAA1ACIADAD3/+f/1f/C/7P/ov+U/4L/c/9n/1j/Tv9B/zj/Lv8o/yP/Iv8i/x//If8k/yr/LP80/z3/Rf9R/13/bf9+/4//n/+2/9D/5////xIAKgBEAFcAbwCHAJkArQC+AMkA1ADfAOUA8QD4AP4ABQEDAQUBAgEAAQEB/wD5APcA7ADkANgAygC+AKsAnACEAHIAVgA5ACAAAwDo/8v/sv+O/3b/X/9G/zL/I/8U/wr//v76/gH//P4I/wj/EP8d/yj/Mv87/0r/Vf9l/23/fP+I/5f/pv+v/77/z//h//X/AwAWACoAOABQAGEAcACBAJEAoQCrALoAvgDGAMkAzgDWAM4AygDDAMMAuwCxAKkAnACNAIEAdgBlAFQAQgAzACIAEQABAPb/4f/X/8j/t/+q/5r/lf+I/3v/df9u/2T/W/9X/1f/Vf9R/1z/Xv9h/2v/bv96/4n/lf+o/7f/vf/W/+H/8/8AABEAIgAtAEAATABcAGQAcAB5AIMAiACLAI4AkgCUAJIAkgCTAJMAjQCKAIYAgAB1AHAAbABdAFYARwA6ADQAKgAZAAcAAADz/+X/2f/N/8P/uf+v/6L/mv+X/5P/jf+K/43/jf+L/5H/kv+Z/6D/oP+p/7D/u//D/8r/1f/f/+b/8v/5/wMACwARABwAJAAwADYAPwBEAEoATQBWAFYAWQBhAFkAWgBXAFoAWABVAFEASwBHAEQAPQA1ADIAKwAnABcAEwAOAAIAAAD1//D/6v/j/97/2f/V/9H/yv/K/8f/xP/C/7z/vv+9/8D/uf+6/77/wf+//8P/yP/I/87/1P/c/+D/6P/t//P/+P8BAAcACwASABwAJQAnACoALgA4ADkAOAA/AEQAQwBGAEIARQBFAEEARgBKAEMAPAA9ADcAMQApACUAHAAWAA8ACAACAPv/9P/u/+f/3f/Z/9P/zf/J/8f/xP/B/8D/v/+//73/wP++/8P/yP/H/87/0f/V/9T/1v/d/+H/5//t/+3/8f/1//z/AAABAAUACgAKABEAGAAWABkAFQAcAB4AHwAcAB0AHwAaAB0AHgAYABYAGAASABUAEQAUABQAEAAOABAACwAKAA4ABgAJAAEAAAD9//v/+P/0//X/8P/t/+v/7v/p/+j/5v/k/+b/4//k/+P/5P/l/+X/5//k/+T/5v/m/+r/7v/x//X//P/6////BAAGAA0ADAAPABEAGQAVABYAGwAeACMAIQAfAB0AIAAfABwAGAAZABkAGwAVABEADgANAAYABgAFAAEAAAD5//j/9//0/+7/9P/w/+3/6f/j/+T/4f/d/+H/3//c/9//1//f/97/4P/k/+L/5f/n/+n/6//u/+//9P/0//b//P/8//r/AAAFAAYACwAIABEAFgAVABoAHQAfACEAIgAkACkAKgAoACcALAArACgAJwAnACQAHwAgABwAFQAXABgAEAALAAgACgACAP3//v/4//T/9P/y/+3/6v/k/+X/5f/g/+D/4f/g/9//4f/f/+P/5v/n/+f/5P/m/+f/6v/u//D/8//0//T/8//z//T/9P/7//r/+f8BAAcABwAJAAsACgAQABMAEgAVABcAEQAVABwAFQAZABsAHAAWABMAFAASABEADQAPAA0AEAALAAUAAwACAP/////5//r//f/z//f/+f/6//P/9f/0//X/+//2//f/9P/1//3/9v/z//f/9P/0//L/9P/2//j/+P/6//3//v8AAAAABgAFAAUACAAGAAwAEAAPABIAEgAQAA8AEQAQABIAEgANABYAEwAQAAwADgALAAoACAAEAAcAAQAEAAEAAgAAAP3/+f/9//v/9//1//L/+f/0//X/8v/w/+z/7P/t/+z/6//v//H/8//z/+v/8v/z//X/+f/9//3/AAAAAAEABAAEAAoADAANAAwADQANABMADQASABYAEAAQAAsADwAOAAwACAAJAAcABQAFAAIA//8AAAEAAAAAAP7/AAACAP//AQABAAAAAQACAAEAAAAAAAAA/f8AAAMAAAD+//n///8AAP7//v/9//3/9//4//j/+P/1//b/+v/3//j/9//3//P/+P/+//v/+//4//n/+v/7//z/+f/2//j/9//4//z/+v8BAAIAAAAAAAIAAgAGAAoACQAMAAwACwAMAA4ACQAJAAoACgAOAAoACAAGAAcAAQAAAAQA/v/8////+f/2//f/9//8//z//P/8//r/+f/9/wEAAQAAAAIAAwAAAAYABAABAAIAAgABAAAAAQABAPz/AAAAAAAAAwD9//7//f///wAABAACAP7/AAD6//z//f/8//v/+v/7//r//v/7//7//v/7/wIAAQAGAAIAAQAEAAEA/f8BAAUAAgAGAAIAAwD8////AAABAAEABAABAP3/AAABAAYABQAIAAQABAAHAAQABAABAAMAAgABAAQAAgAFAP////8AAPv//P/7////AAD///7/AAABAP//BAAGAAIA/v8AAAMAAAADAAEA+//9/////f8DAAAA+//9//z/+f/9//////8AAAEAAQAAAAIAAwAFAAQABgAFAAcABgAJAAYAAgADAAMAAwAGAAYABQAEAP3//P/7/wAAAAAAAAAA+//8//v//P8AAAAA/f/8/wAAAwAAAP7//v8AAAAAAAACAAQAAAAAAAMABAACAAIAAwABAAAAAQAAAAAA/v///wIA/v////////////3//f/9//7/+//9//3/AAAAAP3////9//3///8AAAMAAwAAAAIAAwABAAAAAAABAP//AgACAAAAAwAAAP//AAD//wAAAAACAAUAAAD+//3/AAAAAAMAAgAAAAMAAQADAAAAAAACAAUABAABAAIABgAFAAIAAgADAAUABQAGAAUAAAAAAAIAAQADAAAAAAD9//b/+/////v/+f/3//j/+P/0//b/8//y//n/+f/4//3/+f/4//3/+//9/wIAAAADAAAAAAABAAAABQADAAwACAAGAAcABQAIAAcACAAFAAcACgAJAAYAAgAEAAMAAwAFAP//BAAEAP//AwAAAAAA/f/8/wEAAQAAAAAAAQD//wAAAwD+/wEABAACAAEAAgADAAEAAQACAAEAAAD///3/AAD5//n//P/6//n/+f/2//b/+f/z//b/9v/4//f/9//7//z//f/9/wAAAAABAAAAAQACAAAAAQAGAAcABwADAAUABQAHAAgABQAIAAkABwADAAAAAAAEAAAAAAD///3/AQD///v/+//8//7/AAD8/////f///////P8BAAAAAAAAAAIABAABAAAAAAABAAEABAADAAIAAgAAAAEABAADAAIAAQAAAAIAAgD//wEAAgABAAEAAQAAAAEAAAACAAIAAwAHAAQABAAEAAUABgAHAAYABgADAAMAAgAEAAAAAAACAAAA/v//////9v/6//n/9v/4//f/8//1//X/8v/3//X/+P/5//b/+P/8//z/AAABAAAAAAABAAMAAgAIAAMABAAAAAUABQAEAAgAAAAFAAcABwAEAAQABAABAAAAAAABAAQAAQAAAAAAAAABAAAA//8AAAEAAAACAAAAAAAAAAIAAgACAAMABAAFAAMABAABAAAABAAFAAQAAgADAAQABAAEAAQAAQACAAMAAAAFAAIAAAD8//3/AAD8////+v/7//f/+/////f/+v/4//r/+//9//v//P/8//r//f/4//r/+//+//z//v8BAPz/AAD+////AAAAAAIA//8AAAAAAQAAAP//AAACAAQAAgABAAMAAwACAAYAAgAFAAcABAAFAAkABwADAAcABgAIAAkABwAKAAkACQAFAAIAAwADAAIAAAAAAP3//v/+//z//v/9//z/+//7//3/+//8//7/+//9//3/+//9//3//f/9//z////9//z////7//v//P/9//7//f8AAP7//v/9//z/AAD/////AQAAAAAAAAAAAAAAAAACAAAAAAAAAAAAAQACAAIAAQAAAAIABAABAAMAAQAEAAEAAwAEAAMABgACAAUABQAGAAIAAgABAP//AgADAAEAAgABAAMABQAAAAEAAAD9/wAAAQD+/wAA///7/wAAAAD//wAAAAAAAP7/AAAAAP//AAAAAAEAAAACAP///P/9//7///8AAAAA///9//7/+//8//7//v/8//r//P/4//j/+v/6//r//f/9//7/AAABAAEAAAABAAAAAgACAAAAAwAAAAAAAwAEAAEAAQAAAAAABAAAAPv/AAD/////AQAAAAEA/v8CAAAABAADAAIABgABAAUABgADAAYACAAEAAgABQADAAYAAgAFAAUABwACAAEABgADAAQAAwAEAAMAAQADAP////8AAP7//f/7//z//f/7//z/+//5//n/9//8//v//P////v////+//n//P/9//7//v/8//z/+//9/wAA/P/+/wAAAAABAP//AQAAAAIAAAABAAQAAQACAAAAAAACAAAAAQABAP3/AAD9/wIA/v/+/wAA/f8BAP3////////////9/wIA/f8AAAEA/P8BAP//AgABAAIAAQD+/wIACAACAAUAAgAEAAgACAAKAAIACAAIAAYACQAGAAcABwAFAAcABAAJAAYABwADAAQAAwAJAAEABgD//wgABAABAAEAAQAGAP3/CADy/woA8P8PAOj/DgDj/w0A4/8QAOn//v/u//f/BQDr//3/z/8XAN7/MACo/wUAx/9EAOn/BQDC/wIABgAOAPT/1v8AAPH/LADo////0/8fAP7/JwDs/wgA8f8WAAkAGwD6/xMACwAPAAUAEQAMAAcAEQAGAA4ABwAWAAgAEwAPABUADwAYABEAEwAPABQACwAPAAkACAAAAAEA///+//v/9v/4//b/+v/z//f/9f/3//b/+f/y//X/9P/z//L/9f/2//H/8//z//H/8P/w//D/8//v/+f/6//4////8//e/+f//v8OAPz/4f/s/xYAHwDu/67/mf9x/+j/3//i/w4As//FAd0A2AC1Aaf/TgB9/hUAEwAS/E75vP88ENgCH+acC/MgGeI78t0fdveA7lYVy/577RAP7gPx7PsGFwgR9loB+wMxAtD2xQr0/Mj7aQlp9osI8fqW/VMCd/yaAv78hwGCAPr9uAJ8/d//AgJD/pABZP8YAAQAAQCI/3T+CgF0ALj/av9JALYARf8MAG3/qgCJAJX/RwC6/yEBWf9x/0YAngAFAcf+bAAoAE8Ap/+w/4QBRf8O/1cAcQG0/2//WgGCAb//u/9mAS8Avf4PATQA6/1gAUgBtv7z/b0BvwEb/Uz+RALEAPL9PwClADYAv/6y/rABpv61/i8CVP+4/vYBXAAl/XEAEAHM/SD/FgKQ/6H9IQK+ADv+kwABAXH/rP/RAOD/fv9h/70AWgDz/hYBiwAk/9QAJAAN/48AwQGW/wf/IQKsADT+7wArAJb+2QCFADL/8QDj/7z+WALR/w//UAE5ANj/XABp/40AFgHH/nb/BgGMAAL/of83AEEAXv9a/2QA+v/H//b/ZAAZAMz/q/94/gECQADi+zwCowJz/GH/xANl/lr9kAIaAHD9tABdAc3+3/4JAcUAL//u/ycA8f8YAIkA9v6h/zQCr/4L/+sBR/+I/qMBGQBJ/UIB/wEA/jP/ngJDAIr9TgEEAY7+2QBzAMb+0gAAAcH+1v/RAOX/cP9zAFkAZv9VAIgAqP+B/70AgwA7/9QAeQAK/8f/8wAzAK3+bAGjAGH+RQAuAYT/x/6fAT0AJ/7dAP4AVP+k/7kAXAAC/8/+t/+bAdkA8P97AB/85fzyA0kEOACm/ff9fv3g/8QDigF7/27+uP0R/4ABgQJIAKf+cf79/sYAeQGdAKH/5/4O//3/AwGiAEwAiQAl/7T+FwB4AJgAVwAxAJcAbv/0/jcAwQDA/8f/ewApAJYA4f90/20ABQBf/37/FAGLAAj/BQGaAB/+if9dATcA9f9oAJL/nf+6/9T/ywAsABT/WQCHAID/KgBZAGr/Rv8QAJUAFgB0/1sA8wDq/zf/1v/5/6H+8P/AASkAwv/f/2v/r/+6/9YAsgDm/n3/QAGk/1z+QQEcARf+qgAxA67+zf3PAQX/TvytAboCnv6jALwCxv7V/rAAHf8S/tb/1QCpAPgAVAFCAaP+Wv5w/93/jv8aASQBrv+o/w8AoABZ/zIAbABt/mn/VABmAAEAoQEVARP+GAB4ABD+tP+dAQgAvP57AIgBTP6lAN8B0f64/iT/WAE///H+dALj//H+1ACOAWD/W/2EAcEAHv1LAYEBXACI/jD/ZgMm/bkA8v/W/4z+rPzmBif9dAFfBcD7Lv+l/dL8vQBj/3kFtwP//d4CTPyM/D/9Rf9yApEBTANiAnD/KP2D/xv+E/89/+r/UgLaAPgCyQGL/f0B4PfyASH8K/83Bd/8QAlh/jQCk/96/cv7Pf7s/fgChP1FA3wGjPupBa3+aPqL/y7+8vxABC/+YQrD/JD+oQTL+AX+Uv47Akj8tQQmASD/JQWB/ZMCwP+I/QkA7PYrAV4AswOoBkH/kQau+Qj1XAg7+l4AfQeK/nkH+/eU/y/7avueCsf6cwU+C0P0TPsGBLL5mv0XB3gEKP7q/5wAHvpx/ykEUfmMCb4CmvSWCHP5ovtRCiL/oQep9r3/OQX17zoFjwHsANAJoAGa/XQARvYc/PkCO/usAUcKU/9eBPADKfcbA+P3W/+L/in9KwlE/PoDaQc5987+2QIv/vUEfPqHAB0BNP5VBF/5mQXDAZn6/wHzAcb6zwSCAQn7AAS/9kUCiAaZAhUEFfyn/OX5z/v2ArsCxQS2AAYAH/80Bbz6xvfjB5T+Hv9KAzkBuPyV/zz7WwBbAIACrwzw/Cz8BvxN+K0B9/3QBB8J4Pg2Dk8CxvLC9rb1/whQBKsCNg0E89387Ast+4oCCfPmAbcGAPpCCJ//VvrVBt8AzgL89/b5yAcB+lMAoweSAIoAtvyv+x4LNvtCCdf+wuwc/ysDPAFZAikBkAVVCd/26/xg//0CB/nI8uII/A3q/goIvvrz9y0D8fN1/wsAHAMrD2gAFQStAfDvd//K+r//rQdt/P/+fv/sBEUHzwHwAP76f/UU/pIFSf9TAIUFwf6F/Fb63QJICOn6KP0M/4ECXAO+B0kDPfpr/kLvTwAfDsb9Af4zAE0Mjv5R8jH/+gCgCgL/TfeLBPUGtPdB/nQCdwbZ/rTrkAChEU0G6/VT+8MCNAdN9Rn4eA/oBnv8yfix+5cEVv9FATwKTP3E9e36GADKB84GfwNdAH/2fQA3/SH6/wWKAPwGbgCi+cD/Zv92/NIFWQhC9pz9NABv+pIECwhZ//oCMwOH+t/1UvzcAYv/NQZSBi8G6Pwn+lYGKfuB9iYDJ/9nCMEEiPSyAdYLWwPY99rt4gMmDln3FftwBhYI8QIf9KP60Qy6AOb1f/VFCOcNzvpj+wQDVASy/kr17/0ICj0Gj/gI8iEI5xCF/Hr0hQDMAj8AiP6p/WYIkwK39nz9CQLPBFUBcvtRByYIBPYP7e/4nwkODD0IwwCCAmX+Evxj/MrwwP3fD9EHKgSF/pj4xAJKAuz7c/fR/qAFawRq/4H+bwF2BfAD3fh58rv7gQpnBG39TAHg/3L7jP1M+B0CZAotArf5v/Yo/mwDKAGpBAsHn/0F/q76W/u2AWUGagiPBaQA/v+K+fX8RAKF/9QIfgc7AIj7Of2A/8j6n/xWCL0E3f9V+ub0N/zI/pP6CwCzBKMA0/5p+yP/JgBF/MoC1QeqAy8GQApbB4cDTwQoCFoKHgYyBnYIZQm2BGf5jfRF9NX7HwFZ+Kj1tPKT6ZHrZuqh6ufsuumO8lb37PBP97P7h/cK+a0EAhT9HFUlICcQIqwiUR56EtgKow3YHqsgRRNgCJb8d/j97OTfFeCW5GLnweLX2O3XHdv92LvPa87X3dPoZN1J+NJPMXF6PKIC5u+l9o7yPfNpGvRGSGOfSgkQAQLbApXn4NYj6N4PTyCZDD//mvi56EDUILwFrxrAa98C8arp2ugd8hnZddV3LLlyhFfkHwD/CO2C7LzvOPycLzto6WxxNh3xY/peC0fgr9Vr+0MXzyAODn/zKO7x3AjDsKsEp93Fy+WY3+jg7vFZ4w7ChRNUdexdmSQnBevq9+ZD7Z3zCiS4aOB9S08hE9Phx95J/CABAgHVFUcdZBh09BHX+NXp2BfIfbgPu2zK0NZB30XoN/LP4cHook3qcxA2MAjt8pvh8umQ9eoMWkr/f+tojzPr/CbHNslX+zMPDRbdIJ8dJAvK6XrLfsIJx8jH+sx61RPV1sqT19LkM/Rc2bvs7V2Vdro6iwbm6yXphPHe68P7WEMjdXRqEjyJAbjRddYL8YPvvAAtIy0qJh7HB0bgvsOOuT25hsvu3cLcmua28ODtC+944VL/8Uz/W9gxGg9K/pD1X/lr89H7xyQkR2NPkDcCDgHvd/A38dzkrOaL/wwQqxixFsH2RdVdxLnDgdMT3FTYj+bhBSYP/QVG+XvxgQNADMgDoALOByYcpiy6L70sFBX6BvAFBwh8DRQP/ANY/d3//AG+/VztXvDi+dH1R+fX6Zf8SgCB8WHuLfqdAyoFPfik7Vvx0vaD7TvoO+lQ8UT/tAQ8BWb/1vH17Mf06gGpDc0LNwSsCLcVPRlVDC8C1wmtEtsRjg8QGiIabAsbAFoHFxbGF7ENXgWmB8oEXPvQ7lPoQegY8/b5mP1FAMTzO+RZ4izmTuih8aDzgPQHAUUHHQMH+jj0c/V5+1MC9QjeD8QNIwVbATMLyxY5FbUHpwUlD9QN5AZnBx4FhQEA/5D6df6p/TjyZuqa8mD98Pz598X3Yv3kAQH/Qvj/+G/+fgAGBIoKowzyCVsFLANXBZ8ImwhuB9YHxwYDAqP+ywPRBQf/5fgz897uWvPB+KXyeu0v90oEUQTM+0X3BvyEAm8EngRIA4wFyQ3KEZMNYgZMAkEFJQkwCKkFaAUvBoID6vvA9RL2avso/o37zvTR5rfe3edk8Trt1utp+s0HsAWC/fz60f3uBCoLcgsyCnUNNxT6F5MS/wWu/z0GJg6DDGMHzghxCvgE9P+0+/L6lgCwAYf9/fVY6m3ppfEZ9lf4G/iw+nIBh/+A+TH4Y/ncAS0KqQgTBQoGRQlgCp4FC/5a/HADDAk4CUQIYwNR/rv97/x9+ln60/01A+8CfPn18C30W/wx/Ab5sfsAATYD7wBn/zz/NgCqBh8MyQmxB5oHWwgFCSgFvwFkAD7/pf7z/Sr8JvkS9U31xvht+338JfvZ+nH6Ivf89gH7G/51A28HsgXAA2EDFAROBg4HjAlTD6URsQ7UCX8FUwT4BPsD6wGv/0//mv8d+7X07PDO7lPx7vdO+y/5Xfe09pP11vde+xj7xPxtAnAGvwUCAWX+IQKrBxQKAguUDFoOiw2cCL4EigXyBXkEEATGAff8Svvr+vr3ePIu7c7v9vjj+6f3gvRd9M32jPor/P76qvvy/1AFnQaiAnEATAbNDakOlQxDDB8O1w8DDr0KBgl/Bw4I2AjcAzT8APlp+V35c/Wt7x3vxfPK9ZDzFfLO8n31kfjO+Xb54PoX/iECeQSCA1kEQwqIDqENFQzZC1MNmA7VDc0M0grqB5IG0ATu/yb6vfc3+CP4lvWd8vrxpfJI8VTwAvO49pr4H/lo+u/8N/5Z/hUBLwRSBeEGVQqNDDIMfwtPCgQK+QouC/0KHQovCCUGKAQoAFH7wfg++OH4gvi79c7zHvQf84LxKPMY94357/n6+Zf7mf1C/nT/twEgA0YFqggcCq8JXAlECUgK/QtjC58JDQmICSEJwwZAAtD+OP/y/+P9hPp0+FX3t/Um9BT1Rvit+jX6Pfh89+v4GvuY/Er+6ACGAoECPwPxBKAFvgSKBL0GKAgQB3UFgAVqB7AGBwLv/kwACwN6Asf/VP8CAFf+qfkJ95T5jv0+/+P++P2C/en8T/zT/Jb+MQBmAEEBFwMUBJECJgAnAP8BTwJvAHH+Iv/wAe4C2gBF/lP+cgDfAIL/sv6l/tn+Q/6z/Qf+qv+xARACYQFYAToBxQAJAUEBPACs/sD+QQGmApAAbf4z/6QAdP+z/Iz7ev1eADUBTAAWAJIA0AArAI//7P+KAFsBFQIAAtEB5gKpBMcESwN9AmUCRAOhBBwEWAFL/5X/5gAPAQcAmv9DAFf/IvyA+YT52vua/XH+rv/PAMAAO/+q/Sz+P//L/80A6AGAAqcCogKgAvgBaQDi/tL+vwAmAkgA//zC+6T8Yf2q/EH8P/28/cv8cftd+l37iP1K/g7/RABgASwC9gGNAfwBGwP0A5QERgUwBgcH/gYEBusEqQPTAvkCrAKwAZv/jP0v/dP97/0c/Sn8sPvh++37xPoe+mD6/vp3/Bf+MP8yAOgBMALsAF8AswGaA9oEAgWyBV4HwAebBlYEDAOPA2sEtAN2ASj/BP7H/f38ifsu+pj5Hvkg+Pf2UfYG99D3bPgS+tT7RP1V/zkBJgEEAeUBMwN/BA4FoAXuBkkIawi9BqoE8AM2BKYEYAQGA1QBLwAOAEMAQP8Z/m794vy8/Cj8svs+/Lj8sfwc/X/9OP65/1QAAADz/6kAZQGHAUgBtgGFA3wFLwUoAxUCLgK/ArUCoQFVAGf/sP5m/lX+F/6w/e38EvwB/BD80/tO+0z7ZPyt/X/+Bv/6/3IAOgC3/3T/1//GACwB3QF0A3EE+wODAkQB6wBgAdkBEwK6AT0BvAC7AN8AhwBi/yH+M/6//vX+2v6Q/pP+Mf+X/3P/cv9sAOgAQwA7ADsA9P+d/5f/wgBZArUCxwGaAAAAFgAGAJD/0P8vADgAJQB6/3b/u/9f/9b+I/95/+v+ev6Y/uf+uf8xAAwAwf89/7f/RwBRALP/kv/r/2gA1wDrAJ4ATgBMAM///P5h/hr/hv+m/7P/Rv9w/xIAlADT/3P/agBFAWsBpgCbAHUAPwGmAv8BPgHL/54CVQPDAFj/EfxZ/Ij+R/xO/en9sfvoCOwEnQIBCa7/RAI7Asv2a/lF9kz5RwW7+Mf9AQZ0AEYAfwAu/ssBMQF4BKoEDgEfAwkE/f5B+s3+APvD+iv/cv/2/vwCUAJlA/ABLQPGBHEAgwPNBAUBmAIpAtj9xP/r/ob+Wf4XAhEByv5aBlAAEP6FAmsBxQI7+uUBCQYi8/D/Zv+i9lb+lffeAUj9UflMCfj4Iv8EBOP3qgQh+wL/UgPX+NEES/zD/LsGz/ibAzUCFP4cAsz8KAbx/Wz9awbK/I//uP/p/Hn/OvsGAxv+rv0pBiv/UAABBAv/WP2O/tkAR/0E/wEFM/7TAUIEx/+Y/jwBRQMn/mkBiAMP/psCfgBQAHsB6vwQAXL/hQCa/6799wID/7b+PwEq/xUBJACgAen/fP7tAS/9bP81ADf+qAC+/iEAiP4+AHIBUf2dASQAHP6LAHz/IwBfAOUBsf/7/xECE/9M/0sAmf8f/u3//v4v/d3+8v1z/Yv8qf1D/dv7P/+P/lL+IACB/pb/TwAXADsBgAGpAusCdgPTA7YCdATyBa0EOQZbB18GiQVBBpQE8gOMBLQAfgLJACT+SP7Y+0z7/fiv+JL4SvXp9uH1+/QJ95j1y/gZ+fv56Pyf/J8AngKVA90IEwoHDcQQShG7E1wUwRQ3E34S6BDbC/IJ7QUUAEL8kvc+88PuoewE6vTm5uWy5Cnl7eOk5oboEeuT72Dx0PcY+Rj/3gTgBuwPcxEfF1QbNh3XH6gdDiCRGxoanhimEtYPqwpSB+IA5Ps2+Ezya+8I7LDpMuf85VTl9eMQ5XPlgubD5wzrYe3J71r2a/r6AF8IrA7CFXAa2x9hIpQiWCLTIDwdwBg3FbEPkgrBBhUDVv70+1L6NfYS9lD1hvHt8f/unOu36oXle+SR4AreY9/d27ffr+GE5VrtF/MH/hQF/Q6XF20dwiM8JVAolSbnI74hBBwzF3kRfwtjBV8A6PtX+eT3Cfcp+CT3jfgV+PX1+/WU8ozw9e6h7CzrlOni6WfpMOpE7f/vwfTO+1UCDQphEgoZDyBtJEonkShrJzglAyCEG40Urg3KB1oAjvyx9nr1kfQ186b2ivb4+O76Fvvc/D/7dvoe+QX1N/Pi7hzrz+mU5mLmrujf6Tvw7PUb/agFIQvwE4wX7RvWHvId1R4bG6oX7RNoDfMINwPM/WD7NPYd9vD1sPRX+cP4pPsU/Qz89/3O+a75uvVP8VTwxOlJ6R3mk+Sq5srmduzt8Ib43ACiCP0RWBjpHoMjhSUZJ18msiO8IPEbOxYJEXkKDAXg///65Pfy9OHz2PJ68vzyiPKI8uzxBPGY8Bfvgu7N7XXsJ+1m7CPteO9z8Tf2C/u2AGAHPA0xExsYTRsuHsceix4uHdIZTBalEbgMRQdhAh39/vg39UvyYvGp7//vufBx8dHykPNc9O30B/Us9WH1zPTt9JT1xPXC9pb4QvqV/WoBjQRfCUMNnRATFLEVxxbXFq8VVBQYEdQNPwpdBWoBj/xn+NH0OvK/8DnwpPCz8fT0xvW79mL4fviM+PX4IvmO+Ir5L/ki+eX5RvoV/F/+0QE8BfIIZgzED3kS6BN/FVAVchT1EoYQ4AzICB4FvACW/Cf5WfZV9IXzqvKF8wf0vvR09rP2hffb9pX2k/bu9aj2AvcY+M35zPo+/Wn/rwGrBQgJ9wyuEFsTFBY4FwcYmBeLFuMUcRLpDzAMEwmfBNAA8fwx+X72o/MZ8sfwAPAl77Huje4v7nDu4+627+LwQPIg9Pb1E/gA+wP+nQGQBb4IggyND54RQBOtFCIV9xRxFMwSvhEdD5gMOgokB8QEtgHb/kH8v/nJ9qXzWfF+7jbs2urH6U/pXukU6vfqlOwV7+XxYvWu+bP9dQISB/QKuA8mEwAWrhgZGg8bFxvQGQQZjheYFO8S3A9jDKcJdwXIAR/+tfkV9k/yMe4x64fo7uXc5CbkyeNH5aDmgujg6xrv3/Kc9//7egBXBYsJ4A3TEUkUURZMGJcYZxiZFzAVYxN3EJQNZwuKCPwFaQN4AK39I/sV+Ir1X/Ov8JfuOe2L66fqJepS6kTrQuxJ7nTwGfOR9sn5af1GAaAEoghqCxoOsBAVEiYTrxPMEy8TgBICEXsPog2QC68JgwdNBYADBQGv/qv8R/oc+Nj1afQr82LyrfGP8fPxefJ28xz1aPeB+QD8T/5xAL4CqQSaBqUIDQoeC78LXwxADFgL2AqlCSMI3gZEBWsDXQHW/tD8qvqp+HL3xvVh9LzzvvJE8nLyMvIu8330z/WA9/r4Dvsr/TH/PQE9AxAFgQYPCDsJ7AnMCi0LdwvPC10LIwsFCw4KSAnGByoGBwXHAgkBxv5y/LH6ffhV9zP2fvVo9aX1evZK90T4zfln+6j8/f33/vv/9ACkAYECAwN9A38E2wRhBRQGXQalBrsGbQY2BswFzQTmA00C6ABi/7H9DPyT+jT5v/cG9yf2ufXw9U72/vYR+AH5U/r6+0n9xP6CAKMB7wIXBGMEqQUfBl4GIQcPBy4HYQdRB5QHYQcJB8oG4AUsBe0DkgInAWf/9v1P/KD6TPky+BD3Q/YZ9ib2Q/bu9qr34fhJ+lD7uvwL/pH/qwCSAZkChgN7BB4F1gVPBoEGlgbcBgsH3AagBgwGaAXhBLgD1gIGAhkBLgAE/1D+Jf2F/Az8KvuX+s/5pPmg+VD5s/kO+kT63fpT+2D8Sv0t/mH/UgA8AQgC5gLtA6YEBgVqBZ4FxAWcBaMFYwWkBBAETwOZAiECFgFPAAkAAv80/uT9eP0R/e78wPy7/Lz8sPzs/FD9dv2q/TD+cP5a/xgAnABdAc4BGALZAn8DnQMvBCQEPQQPBKADcwOYAtwBTwGXAMj/Av9b/sn9Vv2U/Bn87/vE+yL88vsV/JT8yfxQ/Rr+qP49/wsAlQBTAdABdwICAz4DrwPZA8UD4QMOBBAE1AOVAzgDygKzAjMC5gGCAdAAeADQ/wP/pP4s/pD9RP38/JL8oPyk/IX80vzN/CL9Zf3T/Y7+6P5//8n/AACWAO8A/wBfAW8BiwHJAd0B5gHqAbwBZAEfAe4A0ABKAEgA0f9J/wb/j/5W/vL9r/17/Uj97fz0/En9ef2v/R7+U/7Q/jr/hv8/AKEA/QCFAQ4CdQK0AgEDUANCA2ADYgM1A2IDCwOrAn4C8gFkAewAqgAxALf/gv8g/8z+yf6w/qb+yP65/hX/av9z/7///P8RAC8AQwB9ANcA8gD5AAIBKQFMAUIBbQGCAU8BXAEHAcEAtwAuAPb/wv8y/8n+b/4Z/tb9d/1W/TX97fzy/BT9KP1m/XL9jP3J/fH9Pv6z/gj/If+Q/6b/GACFAIsANAFZAXUBtgGwAe8BDgLiAfYBzQFcAU4BFwHlALsASwAiAMH/ZP+A/3v/aP9m/2z/Wv+O/8n/HwCTAKgA2ADnAP0ARQF1AYYBvQG1AVQBeQFaAUMBQwH7ANMAawA1AB4A4v+k/3X/JP/L/nf+Sv5p/lr+Qf4a/hf+IP46/pT+y/4t/z//TP+S/77/IQBXAJIAswCsAJsAugDmANUA6AC1ALgAjgCHAKwAhwCAAFQAXQAtAA4A8f/i/93/f/9b/2D/Gf/p/v7+z/7K/r7+yf4J/wr/Nf9m/5T/rP/o/z0AawCcANEABQHhAAkBRQEyATIBLgEJAfQA5QCgAI8AewBLADIA6f+y/7D/kv9o/17/Wv8R/wX/Hv/4/hn/R/9I/1r/hv+4/9j/IwB4AJsAvQD6ACUBQQGMAYcBcgFyAVUBUwEuAd8A7QDOADgANQACAL7/uP9v/1v/OP8l//7+0P7x/hT/8/71/hL/4f4X/y//Ov+G/5n/l/+5/wcACgAnAEcAYACdAI8AqADSAMgAzADTAOMA1ADEAMYAqAByAFoAYwAiAO3/uf+W/4b/S/8q/yv/9v7i/hD/9P4V/w7/Bf9b/2T/Z/+O/8b/6P8TACUAXACVAJAAuQDVAAgB/QD9AB4BDwHoAM8A2gCsAJoAagA/AEEAEwDW/8j/vf+J/4X/e/+A/37/Zf93/4f/nf+P/5X/tf/M/+P/5f/o//z/QQBIABkAHAA6ADsAJQAIABYALQAEAOX//f8EANT/x//2/wIA4//e/+L/6f/0//f/5v/q/xIAEwDz//P//P/w/+n/3v/s/+r/zf+7/5P/nv+//7n/u//D/8r/u//N/+v/EgAZACIAWwBIADwAWQBEAEsAVQBPAF4AKwAcACUAEAAVABMA+P/1/+r/8v/u/+7/FAAdABIABQAwAC4AGAAtAC0AKAAdABQADAD//wUA/P/d/9v/5f/F/57/wv/j/8r/vv/A/9X/3f+7/8n/8v/z/+n/7f8HAAMABQAWAAcAFQAlABsADgASABgADgAWAAwACgAVAPn/8P8KAAkA/f/w/+D/7v/r/9v/y/+6/9f/2v/D/8r/1P/V/+T/8v/n/wAA9v/w/+n/CQApAPz///8JACYAEgARAB4ANAA+ABkAMwBHADYAQABNAEYAXQBNADMAOwBTAEcAMgAmABAABgAAAOv/1f/c/9f/uP+m/8X/wP/H/8b/rv+4/8X/0//Q/+L/5f/P/8//3P/V/+X/+P/o/+f/8f/n/+f//f8FAAkAGAAJAP3/CwADAAAAAAAHAAEA+P/x/+z/3P/d/+v/2f/G/7//0P/X/9n/0f/V/+///v8DACEAJwAbAB8ALgBSAFwAcQB5AGwAaABiAFgAdQCFAHcAZwBOAEQANgA9ACIAHwAfAAUA/f/x/+//4f/j/9r/zP+z/6P/uv/F/8z/uP+n/8P/zP/J/8n/2v/i/9H/4//y//7/BgAPAB8AFwAWAB8ALwA1ADYAIwAJAAAACAAWAPz/+v/m/9D/wv+y/7H/tf+6/67/vf+p/6n/v//V/9b/0P/R/9f/1v/C/+n/8v/9//7/+P8AAAMACQARACcAKwAtADQALABCAFoATgBfAFAAYQBPAE4AXwBJAFYAQQA2AB8AJwAUAP7/DQALAOb/yf/d/9b/2//Q/9D/0f/S/9L/0v/y/+f/2v/f//n/+f/z//3/AwASAAkADAAZACMAFQAbACAAFwAOABIAIAAnACUAAQAMAA4AFwAbABwAEAALABkACgAAAAUAEAD8//n/7f/s/+j/6//u//P/6//E/8T/0//a/8//2f/Z/9r/1v/V/+H/9P/o/9H/6//z/9//3//3//7/9//5//b/6P8EAAAA+v/9/wAAEQAMABoAJgAiAAgAAwANABUAIAAiAAUABgAPAAAA7v/x/xEACQADAP7/AAD5/wcAGQAMAB8AGQAOAAUAFgArACEAGAANABkAAADu/wUABgAAAPX/+v/q/+3/+//1//P/BQAEAOr/7v8BAAAA5P/o/+n/8P/m/+b/5//r//P/5v/p/+D//v8GAAUAEQAKABEABQAYABsADgAVAAQAAADx//n/AADw//H/6v/j/9n/7////+v/7v/u/9j/zf/i/+7/6f/v/93/0//e/9r/6P/z/wAA7v/1/wQAAQAaADMAMgAlADwAOAAnADkAPwBJAD0ANAA2ADUANQAmACEAIAATAPn////q/9n/4f/g/9j/uP+z/7j/uf+5/7//wv+x/8j/2f/a//P/8v///wAABQAOABkAMwAlADsALwAwADkAQwBEACQAPQAsACkANAAyADgAPAApAAAABQARAAsABgACAAAA6v/i/+f/4P/l/+z/7v/2/+b/6f/0//n/BgAUAAEA7/8AAAYA/f/2//z/1//M/9b/1f/N/9P/zf+8/7L/xf/X/9X/5//W/9v/1v/i/wcAFQANABoALwAPABwALgA7AEIA\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 음성 재생\n",
    "ipd.Audio(test, rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#차원 변환\n",
    "test = np.array(test).reshape(-1, 8000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_num = model.predict(test).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_[ans_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-93-682ee36908c4>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for wav in tqdm_notebook(test_wave) :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f5f8fb1ed34fde9cc883a993a4265f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=158538.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8000, 1) for input Tensor(\"input_1:0\", shape=(None, 8000, 1), dtype=float32), but it was called on an input with incompatible shape (32, 1, 1).\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1122 predict_step  **\n        return self(x, training=False)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:717 call\n        return self._run_internal_graph(\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py:207 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1106 __call__\n        return self.conv_op(inp, filter)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:638 __call__\n        return self.call(inp, filter)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:231 __call__\n        return self.conv_op(\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:220 _conv1d\n        return conv1d(\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1655 conv1d\n        result = gen_nn_ops.conv2d(\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:965 conv2d\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:593 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3319 _create_op_internal\n        ret = Operation(\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1816 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1657 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 13 from 1 for '{{node model/conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](model/conv1d/conv1d/ExpandDims, model/conv1d/conv1d/ExpandDims_1)' with input shapes: [32,1,1,1], [1,13,1,8].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-682ee36908c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mwav\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_wave\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#예측하고 답 추가하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mans_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mans_num\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manswer_list\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0manswer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mans_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m     87\u001b[0m           method.__name__))\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mc:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1266\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1268\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1269\u001b[0m             \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1270\u001b[0m             \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    625\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 505\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    506\u001b[0m             *args, **kwds))\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2446\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2447\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2777\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2779\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 2657\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1122 predict_step  **\n        return self(x, training=False)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:717 call\n        return self._run_internal_graph(\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py:207 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1106 __call__\n        return self.conv_op(inp, filter)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:638 __call__\n        return self.call(inp, filter)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:231 __call__\n        return self.conv_op(\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:220 _conv1d\n        return conv1d(\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1655 conv1d\n        result = gen_nn_ops.conv2d(\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:965 conv2d\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:593 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3319 _create_op_internal\n        ret = Operation(\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1816 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    c:\\users\\kbm06\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1657 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 13 from 1 for '{{node model/conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](model/conv1d/conv1d/ExpandDims, model/conv1d/conv1d/ExpandDims_1)' with input shapes: [32,1,1,1], [1,13,1,8].\n"
     ]
    }
   ],
   "source": [
    "# 답 리스트에 추가하기\n",
    "answer = []\n",
    "answer_list = [4, 8, 11, 14, 15, 16, 18, 21, 23, 27, 29]\n",
    "    \n",
    "for wav in tqdm_notebook(test_wave) :\n",
    "    #예측하고 답 추가하기\n",
    "    ans_num = model.predict(wav).argmax()\n",
    "    if ans_num in answer_list :\n",
    "        answer.append(le.classes_[ans_num]) \n",
    "    else:\n",
    "        answer.append('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
